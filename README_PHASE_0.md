# üöÄ TRM POC - Phase 0 (Colab Gratuit - 0‚Ç¨)

**Objectif:** D√©velopper et tester tous les composants TRM sans infrastructure payante

**Budget:** 0‚Ç¨ (Google Colab gratuit)

**Dur√©e:** 1-2 jours d√©veloppement

---

## üìã Checklist Phase 0

### ‚úÖ Composants √† D√©velopper

- [ ] **BERT Encoder** (Notebook 1) - CPU Colab
  - Extraction concepts conversationnels
  - Extraction concepts RAG condens√©s
  - Analyse multi-axes (intention, tension, style, etc.)
  - G√©n√©ration STATE_IMAGE JSON structur√©

- [ ] **RAG Embeddings** (Notebook 2) - GPU T4 Colab
  - G√©n√©ration embeddings 3 philosophes (Spinoza/Bergson/Kant)
  - Indexation FAISS
  - Export index pour r√©utilisation

- [ ] **Mistral 7B Generator** (Notebook 3) - GPU T4 Colab
  - Chargement Mistral 7B (4-bit quantization)
  - G√©n√©ration avec STATE_IMAGE
  - Validation contrainte ‚â§500 tokens
  - Benchmarks latence

---

## üóÇÔ∏è Structure Notebooks

```
TRM/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_BERT_Encoder_STATE_IMAGE.ipynb       (CPU Colab)
‚îÇ   ‚îú‚îÄ‚îÄ 02_RAG_Embeddings_Generation.ipynb      (GPU T4 Colab)
‚îÇ   ‚îî‚îÄ‚îÄ 03_Mistral_7B_Testing.ipynb             (GPU T4 Colab)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ (fichiers corpus √† uploader)
‚îî‚îÄ‚îÄ README_PHASE_0.md (ce fichier)
```

---

## üìù Instructions √âtape par √âtape

### √âtape 1: BERT Encoder (1-2h)

**Fichier:** `notebooks/01_BERT_Encoder_STATE_IMAGE.ipynb`

**Runtime:** CPU (gratuit, illimit√©)

**Actions:**
1. Ouvrir dans Google Colab
2. Ex√©cuter toutes les cellules (Runtime > Run all)
3. V√©rifier les tests unitaires passent ‚úÖ
4. T√©l√©charger `state_image_example.json`

**Livrables:**
- ‚úÖ Classe `BERTEncoder` fonctionnelle
- ‚úÖ STATE_IMAGE structur√© valid√©
- ‚úÖ Taille ‚â§250 tokens

---

### √âtape 2: RAG Embeddings (1-2h)

**Fichier:** `notebooks/02_RAG_Embeddings_Generation.ipynb`

**Runtime:** GPU T4 (gratuit, sessions 12h max)

**Actions:**
1. Ouvrir dans Google Colab
2. Activer GPU: Runtime > Change runtime type > T4 GPU
3. **IMPORTANT:** Uploader les 6 fichiers corpus depuis `bergsonAndFriends/data/RAG/`:
   ```
   - Corpus Spinoza Dialogique 18k - √âthique II-IV.md
   - Glossaire Conversationnel Spinoza - 12 Concepts.md
   - corpus_bergson_27k_dialogique.md
   - glossaire_bergson_conversationnel.md
   - corpus_kant_20k.txt.md
   - glossaire_kant_conversationnel.md
   ```
4. Ex√©cuter toutes les cellules
5. T√©l√©charger `rag_exports.zip` (contient index FAISS + passages)

**Livrables:**
- ‚úÖ Embeddings 3 philosophes g√©n√©r√©s
- ‚úÖ Index FAISS op√©rationnels
- ‚úÖ Retrieval s√©mantique fonctionnel

**‚ö†Ô∏è Note:** Sauvegarder `rag_exports.zip` localement - n√©cessaire pour Phase 1 (Vast.ai)

---

### √âtape 3: Mistral 7B Testing (2-3h)

**Fichier:** `notebooks/03_Mistral_7B_Testing.ipynb`

**Runtime:** GPU T4 (gratuit, sessions 12h max)

**Actions:**
1. Ouvrir dans Google Colab
2. Activer GPU: Runtime > Change runtime type > T4 GPU
3. Ex√©cuter toutes les cellules
4. ‚è≥ Attendre chargement Mistral 7B (5-10 min)
5. V√©rifier benchmarks 5 sc√©narios
6. T√©l√©charger `mistral_benchmark_results.json`

**Livrables:**
- ‚úÖ Mistral 7B fonctionnel (4-bit)
- ‚úÖ G√©n√©ration avec STATE_IMAGE valid√©e
- ‚úÖ Contrainte ‚â§500 tokens respect√©e
- ‚úÖ Benchmarks latence (<3s)

---

## üìä Validation Phase 0

### M√©triques Cibles

| M√©trique | Objectif | Critique |
|----------|----------|----------|
| **STATE_IMAGE taille** | 150-250 tokens | ‚â§250 |
| **Contexte Mistral** | ‚â§500 tokens | **‚úÖ Critique POC** |
| **Latence g√©n√©ration** | <3s | <5s |
| **RAG retrieval** | 2-3 passages | Top-3 pertinents |
| **Concepts extraits** | 3-8 par tour | >0 |

### Tests de Validation

**BERT Encoder:**
- [ ] Extraction keywords fonctionne
- [ ] Concepts RAG condens√©s (pas texte brut)
- [ ] STATE_IMAGE JSON valide (9 axes)
- [ ] Taille ‚â§250 tokens

**RAG Embeddings:**
- [ ] Index FAISS cr√©√©s pour 3 philosophes
- [ ] Retrieval retourne passages pertinents
- [ ] Similarity scores ‚â•0.45

**Mistral 7B:**
- [ ] Mod√®le charg√© en <10min
- [ ] VRAM utilis√©e <15GB (T4)
- [ ] Contexte ‚â§500 tokens (tous sc√©narios)
- [ ] G√©n√©ration coh√©rente avec STATE_IMAGE

---

## üéØ Objectifs Phase 0

### ‚úÖ R√©ussite Phase 0 = 3 Livrables

1. **BERT Encoder** fonctionnel + STATE_IMAGE valid√©
2. **RAG Embeddings** g√©n√©r√©s + index FAISS export√©s
3. **Mistral 7B** test√© + benchmarks latence valid√©s

### ‚û°Ô∏è Phase 1 (Vast.ai - 100‚Ç¨)

Une fois Phase 0 valid√©e:
1. Upload `rag_exports.zip` sur Vast.ai
2. Setup 2 instances (CPU BERT + GPU Mistral)
3. Int√©gration pipeline complet
4. Benchmarks comparatifs TRM vs Qwen 14B

---

## üí∞ √âconomies Phase 0

| T√¢che | Co√ªt Vast.ai | Co√ªt Colab | √âconomie |
|-------|--------------|------------|----------|
| Dev BERT Encoder | ~$5 (10h CPU) | 0‚Ç¨ (illimit√©) | **$5** |
| Gen RAG Embeddings | ~$10 (10h GPU) | 0‚Ç¨ (12h T4) | **$10** |
| Tests Mistral 7B | ~$15 (20h GPU) | 0‚Ç¨ (12h T4) | **$15** |
| **Total** | **~$30** | **0‚Ç¨** | **$30** |

**Impact:** Budget 100‚Ç¨ ‚Üí 130‚Ç¨ effectif gr√¢ce √† Phase 0

---

## ‚ö†Ô∏è Limites Colab Gratuit

### Ce qui fonctionne ‚úÖ
- Dev BERT Encoder (CPU illimit√©)
- Gen RAG embeddings (T4 12h suffit)
- Tests Mistral 7B isol√© (T4 12h suffit)

### Ce qui ne fonctionne PAS ‚ùå
- **Int√©gration BERT + Mistral simultan√©e** (besoin 2 instances s√©par√©es)
- **Tests end-to-end pipeline complet** (n√©cessite Vast.ai)
- **Benchmarks comparatifs avec Qwen 14B** (trop lourd pour T4)
- **Persistance mod√®les charg√©s** (sessions limit√©es 12h)

**‚Üí Phase 1 (Vast.ai) obligatoire pour POC complet**

---

## üìö Ressources

### Documentation
- [Architecture TRM (PRD)](docs/guides/PRD_TRM_ENRICHI.md)
- [Corpus philosophiques](../bergsonAndFriends/data/RAG/)

### Liens Utiles
- [Google Colab](https://colab.research.google.com/)
- [Sentence-Transformers](https://www.sbert.net/)
- [Mistral AI](https://mistral.ai/)

---

## üÜò Troubleshooting

### Probl√®me: Colab d√©connecte avant la fin
**Solution:** Ouvrir console navigateur et ex√©cuter:
```javascript
function ClickConnect(){
  console.log("Keep alive");
  document.querySelector("colab-toolbar-button").click()
}
setInterval(ClickConnect, 60000)
```

### Probl√®me: T4 pas disponible
**Solution:**
1. Attendre 5-10 min
2. Ou passer √† Colab Pro ($10/mois) pour GPU prioritaire
3. Ou utiliser Kaggle (15h GPU gratuit/semaine)

### Probl√®me: Upload corpus √©choue
**Solution:**
1. Cloner repo GitHub directement dans Colab:
```python
!git clone https://github.com/YOUR_USERNAME/bergsonAndFriends.git
CORPUS_DIR = "bergsonAndFriends/data/RAG/"
```

### Probl√®me: Mistral 7B OOM (Out of Memory)
**Solution:**
1. V√©rifier quantization 4-bit activ√©e
2. R√©duire `max_new_tokens` √† 200
3. Red√©marrer runtime (Runtime > Restart runtime)

---

## ‚úÖ Checklist Finale Phase 0

Avant de passer √† Phase 1 (Vast.ai), v√©rifier:

- [ ] Les 3 notebooks ex√©cut√©s sans erreur
- [ ] `state_image_example.json` t√©l√©charg√©
- [ ] `rag_exports.zip` t√©l√©charg√© (critique pour Phase 1)
- [ ] `mistral_benchmark_results.json` t√©l√©charg√©
- [ ] Tous les tests de validation pass√©s
- [ ] Contexte Mistral ‚â§500 tokens valid√©

**Si tous ‚úÖ ‚Üí Pr√™t pour Phase 1 (100‚Ç¨)**

---

**Derni√®re mise √† jour:** D√©cembre 2025
**Version:** 1.0
