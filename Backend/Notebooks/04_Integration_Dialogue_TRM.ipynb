{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí¨ TRM POC - Notebook 4: Int√©gration Compl√®te + Dialogue Interactif avec Plan BAC\n",
    "\n",
    "**Objectif:** Pipeline complet BERT + RAG + Mistral 7B avec **syst√®me de piochage de sujets BAC** et **convergence vers plan cible**\n",
    "\n",
    "**Runtime:** GPU Colab gratuit (T4 - 15GB VRAM)\n",
    "\n",
    "**Dur√©e estim√©e:** 3-4h (chargement + dialogue)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 0 - POC TRM (0‚Ç¨)\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT:** Ce notebook charge **tous les composants simultan√©ment** :\n",
    "- BERT Encoder (CPU) + Mistral 7B (GPU) = ~10-12 GB VRAM\n",
    "- N√©cessite **GPU T4** activ√©\n",
    "- N√©cessite **fichiers des Notebooks 1-2-3** (code r√©utilis√©)\n",
    "\n",
    "Ce notebook impl√©mente:\n",
    "1. Import code des 3 notebooks pr√©c√©dents\n",
    "2. **Syst√®me de piochage de sujets BAC** (annales 5 derni√®res ann√©es)\n",
    "3. **PlanTracker** : convergence vers plan cible (selon PLAN GLOBAL.txt)\n",
    "4. Chargement pipeline complet (BERT + RAG + Mistral)\n",
    "5. Interface dialogue interactive Gradio avec guidage vers plan\n",
    "\n",
    "**Note:** Si OOM ‚Üí R√©duire √† Mistral seul (sans BERT) pour tests basiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö® Pr√©requis\n",
    "\n",
    "**Avant de commencer, vous devez avoir :**\n",
    "\n",
    "1. ‚úÖ **Ex√©cut√© Notebook 2** (RAG Embeddings) et t√©l√©charg√© `rag_exports.zip`\n",
    "2. ‚úÖ **Upload√© `rag_exports.zip`** dans ce notebook (ou re-g√©n√©rer embeddings)\n",
    "3. ‚úÖ **Activ√© GPU T4** : Runtime > Change runtime type > T4 GPU\n",
    "\n",
    "**Fichiers requis :**\n",
    "- `rag_exports.zip` (depuis Notebook 2)\n",
    "- Ou corpus bruts (pour r√©g√©n√©rer embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation D√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation compl√®te\n",
    "!pip install -q transformers torch sentencepiece spacy accelerate bitsandbytes\n",
    "!pip install -q sentence-transformers faiss-gpu gradio\n",
    "!python -m spacy download fr_core_news_sm\n",
    "\n",
    "print(\"‚úÖ Toutes d√©pendances install√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Syst√®me de Piochage Sujets BAC + Plans\n",
    "\n",
    "**Syst√®me de piochage al√©atoire de sujets BAC avec plans associ√©s (annales 5 derni√®res ann√©es)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# SYST√àME DE PIOCHAGE SUJETS BAC + PLANS\n# ============================================================\n\nimport random\nimport json\nfrom typing import Dict, Optional\n\n# Sujets BAC Spinoza (annales 5 derni√®res ann√©es - exemples)\nSUJETS_BAC_SPINOZA = {\n    \"2024\": [\n        {\n            \"sujet\": \"La libert√© est-elle une illusion ?\",\n            \"plan_id\": \"plan_liberte_illusion\",\n            \"plan\": {\n                \"plan_id\": \"plan_liberte_illusion\",\n                \"title\": \"La libert√© est-elle une illusion ?\",\n                \"philosopher\": \"spinoza\",\n                \"steps\": [\n                    {\n                        \"id\": \"S1\",\n                        \"label\": \"Intro\",\n                        \"short\": \"d√©finir libert√© et illusion\",\n                        \"hints\": [\n                            \"libert√© = absence de contrainte ?\",\n                            \"illusion = croyance fausse\",\n                            \"exemple: choix quotidien\"\n                        ],\n                        \"keywords\": [\"libert√©\", \"illusion\", \"choix\", \"contrainte\"]\n                    },\n                    {\n                        \"id\": \"S2\",\n                        \"label\": \"Th√®se\",\n                        \"short\": \"libert√© = connaissance n√©cessit√©\",\n                        \"hints\": [\n                            \"libert√© = connaissance des causes\",\n                            \"Spinoza: \\\"L'homme libre pense √† rien moins qu'√† la mort\\\"\",\n                            \"exemple: comprendre pourquoi on agit\"\n                        ],\n                        \"keywords\": [\"connaissance\", \"n√©cessit√©\", \"causes\", \"comprendre\"]\n                    },\n                    {\n                        \"id\": \"S3\",\n                        \"label\": \"Antith√®se\",\n                        \"short\": \"servitude = ignorance causes\",\n                        \"hints\": [\n                            \"servitude = ignorance des causes\",\n                            \"exemples: passions, affects\",\n                            \"illusion libre arbitre\"\n                        ],\n                        \"keywords\": [\"servitude\", \"ignorance\", \"passions\", \"affects\"]\n                    },\n                    {\n                        \"id\": \"S4\",\n                        \"label\": \"Synth√®se\",\n                        \"short\": \"passage servitude √† libert√©\",\n                        \"hints\": [\n                            \"comment passer de servitude √† libert√©\",\n                            \"r√¥le de la raison\",\n                            \"connaissance de soi\"\n                        ],\n                        \"keywords\": [\"raison\", \"connaissance\", \"passage\", \"transformation\"]\n                    },\n                    {\n                        \"id\": \"S5\",\n                        \"label\": \"Conclusion\",\n                        \"short\": \"bilan libert√© vraie vs illusoire\",\n                        \"hints\": [\n                            \"r√©sumer: libert√© vraie = connaissance\",\n                            \"ouvrir: qu'est-ce que la b√©atitude ?\"\n                        ],\n                        \"keywords\": [\"bilan\", \"synth√®se\", \"b√©atitude\"]\n                    }\n                ]\n            }\n        },\n        {\n            \"sujet\": \"Suis-je esclave de mes d√©sirs ?\",\n            \"plan_id\": \"plan_esclavage_desirs\",\n            \"plan\": {\n                \"plan_id\": \"plan_esclavage_desirs\",\n                \"title\": \"Suis-je esclave de mes d√©sirs ?\",\n                \"philosopher\": \"spinoza\",\n                \"steps\": [\n                    {\n                        \"id\": \"S1\",\n                        \"label\": \"Intro\",\n                        \"short\": \"d√©finir esclavage et d√©sirs\",\n                        \"hints\": [\"esclavage = soumission\", \"d√©sirs = affects\", \"exemple concret\"],\n                        \"keywords\": [\"esclavage\", \"d√©sirs\", \"soumission\", \"affects\"]\n                    },\n                    {\n                        \"id\": \"S2\",\n                        \"label\": \"Th√®se\",\n                        \"short\": \"servitude passions\",\n                        \"hints\": [\"passions = affects passifs\", \"ignorance causes\", \"exemples\"],\n                        \"keywords\": [\"servitude\", \"passions\", \"affects\", \"ignorance\"]\n                    },\n                    {\n                        \"id\": \"S3\",\n                        \"label\": \"Antith√®se\",\n                        \"short\": \"puissance d'agir\",\n                        \"hints\": [\"affects actifs\", \"conatus\", \"raison\"],\n                        \"keywords\": [\"puissance\", \"conatus\", \"raison\", \"agir\"]\n                    },\n                    {\n                        \"id\": \"S4\",\n                        \"label\": \"Synth√®se\",\n                        \"short\": \"de servitude √† puissance\",\n                        \"hints\": [\"connaissance affects\", \"transformation\"],\n                        \"keywords\": [\"transformation\", \"connaissance\", \"libert√©\"]\n                    },\n                    {\n                        \"id\": \"S5\",\n                        \"label\": \"Conclusion\",\n                        \"short\": \"bilan\",\n                        \"hints\": [\"r√©sumer\", \"ouvrir\"],\n                        \"keywords\": [\"bilan\", \"synth√®se\"]\n                    }\n                ]\n            }\n        },\n        {\n            \"sujet\": \"Le conatus\",\n            \"plan_id\": \"plan_conatus\",\n            \"plan\": {\n                \"plan_id\": \"plan_conatus\",\n                \"title\": \"Le conatus\",\n                \"philosopher\": \"spinoza\",\n                \"steps\": [\n                    {\n                        \"id\": \"S1\",\n                        \"label\": \"Intro\",\n                        \"short\": \"d√©finir conatus\",\n                        \"hints\": [\n                            \"d√©finir conatus: effort pers√©v√©rer dans l'√™tre\",\n                            \"exemple: un √™tre vivant\"\n                        ],\n                        \"keywords\": [\"conatus\", \"effort\", \"pers√©v√©rer\", \"√™tre\"]\n                    },\n                    {\n                        \"id\": \"S2\",\n                        \"label\": \"Th√®se\",\n                        \"short\": \"conatus = puissance d'agir\",\n                        \"hints\": [\n                            \"lien conatus‚Üîaffects\",\n                            \"cit Spinoza\"\n                        ],\n                        \"keywords\": [\"puissance\", \"affects\", \"agir\"]\n                    },\n                    {\n                        \"id\": \"S3\",\n                        \"label\": \"Antith√®se\",\n                        \"short\": \"critique/limitations\",\n                        \"hints\": [\n                            \"exemples de servitude\",\n                            \"questions sur libre arbitre\"\n                        ],\n                        \"keywords\": [\"servitude\", \"limitation\", \"contrainte\"]\n                    },\n                    {\n                        \"id\": \"S4\",\n                        \"label\": \"Synth√®se\",\n                        \"short\": \"rassembler\",\n                        \"hints\": [\n                            \"comment passer de servitude √† puissance\"\n                        ],\n                        \"keywords\": [\"synth√®se\", \"libert√©\", \"connaissance\"]\n                    },\n                    {\n                        \"id\": \"S5\",\n                        \"label\": \"Conclusion\",\n                        \"short\": \"bilan final\",\n                        \"hints\": [\n                            \"r√©sumer et ouvrir\"\n                        ],\n                        \"keywords\": [\"bilan\", \"synth√®se\", \"ouverture\"]\n                    }\n                ]\n            }\n        }\n    ],\n    \"2023\": [\n        {\n            \"sujet\": \"Puis-je ma√Ætriser mes √©motions ?\",\n            \"plan_id\": \"plan_maitrise_emotions\",\n            \"plan\": {\n                \"plan_id\": \"plan_maitrise_emotions\",\n                \"title\": \"Puis-je ma√Ætriser mes √©motions ?\",\n                \"philosopher\": \"spinoza\",\n                \"steps\": [\n                    {\"id\": \"S1\", \"label\": \"Intro\", \"short\": \"d√©finir ma√Ætrise et √©motions\", \n                     \"hints\": [\"ma√Ætrise = contr√¥le\", \"√©motions = affects\", \"exemple\"],\n                     \"keywords\": [\"ma√Ætrise\", \"√©motions\", \"affects\", \"contr√¥le\"]},\n                    {\"id\": \"S2\", \"label\": \"Th√®se\", \"short\": \"affects passifs incontr√¥lables\",\n                     \"hints\": [\"passions\", \"ignorance causes\", \"exemples\"],\n                     \"keywords\": [\"passions\", \"ignorance\", \"affects\", \"passifs\"]},\n                    {\"id\": \"S3\", \"label\": \"Antith√®se\", \"short\": \"affects actifs ma√Ætrisables\",\n                     \"hints\": [\"raison\", \"connaissance\", \"transformation\"],\n                     \"keywords\": [\"raison\", \"connaissance\", \"affects\", \"actifs\"]},\n                    {\"id\": \"S4\", \"label\": \"Synth√®se\", \"short\": \"de passif √† actif\",\n                     \"hints\": [\"connaissance affects\", \"passage\"],\n                     \"keywords\": [\"passage\", \"transformation\", \"connaissance\"]},\n                    {\"id\": \"S5\", \"label\": \"Conclusion\", \"short\": \"bilan\",\n                     \"hints\": [\"r√©sumer\", \"ouvrir\"],\n                     \"keywords\": [\"bilan\", \"synth√®se\"]}\n                ]\n            }\n        }\n    ],\n    \"2022\": [\n        {\n            \"sujet\": \"La joie procure-t-elle un pouvoir ?\",\n            \"plan_id\": \"plan_joie_pouvoir\",\n            \"plan\": {\n                \"plan_id\": \"plan_joie_pouvoir\",\n                \"title\": \"La joie procure-t-elle un pouvoir ?\",\n                \"philosopher\": \"spinoza\",\n                \"steps\": [\n                    {\"id\": \"S1\", \"label\": \"Intro\", \"short\": \"d√©finir joie et pouvoir\",\n                     \"hints\": [\"joie = affect\", \"pouvoir = puissance\", \"exemple\"],\n                     \"keywords\": [\"joie\", \"pouvoir\", \"puissance\", \"affect\"]},\n                    {\"id\": \"S2\", \"label\": \"Th√®se\", \"short\": \"joie augmente puissance\",\n                     \"hints\": [\"affect actif\", \"conatus\", \"exemples\"],\n                     \"keywords\": [\"joie\", \"puissance\", \"conatus\", \"augmentation\"]},\n                    {\"id\": \"S3\", \"label\": \"Antith√®se\", \"short\": \"joie peut √™tre passive\",\n                     \"hints\": [\"passions\", \"d√©pendance\", \"exemples\"],\n                     \"keywords\": [\"passions\", \"d√©pendance\", \"passive\"]},\n                    {\"id\": \"S4\", \"label\": \"Synth√®se\", \"short\": \"joie vraie vs illusoire\",\n                     \"hints\": [\"joie raison\", \"b√©atitude\", \"distinction\"],\n                     \"keywords\": [\"b√©atitude\", \"raison\", \"distinction\"]},\n                    {\"id\": \"S5\", \"label\": \"Conclusion\", \"short\": \"bilan\",\n                     \"hints\": [\"r√©sumer\", \"ouvrir\"],\n                     \"keywords\": [\"bilan\", \"synth√®se\"]}\n                ]\n            }\n        }\n    ],\n    \"2021\": [\n        {\n            \"sujet\": \"Peut-on d√©sirer sans souffrir ?\",\n            \"plan_id\": \"plan_desir_souffrance\",\n            \"plan\": {\n                \"plan_id\": \"plan_desir_souffrance\",\n                \"title\": \"Peut-on d√©sirer sans souffrir ?\",\n                \"philosopher\": \"spinoza\",\n                \"steps\": [\n                    {\"id\": \"S1\", \"label\": \"Intro\", \"short\": \"d√©finir d√©sir et souffrance\",\n                     \"hints\": [\"d√©sir = conatus\", \"souffrance = tristesse\", \"exemple\"],\n                     \"keywords\": [\"d√©sir\", \"souffrance\", \"conatus\", \"tristesse\"]},\n                    {\"id\": \"S2\", \"label\": \"Th√®se\", \"short\": \"d√©sir = source souffrance\",\n                     \"hints\": [\"manque\", \"frustration\", \"exemples\"],\n                     \"keywords\": [\"d√©sir\", \"souffrance\", \"manque\", \"frustration\"]},\n                    {\"id\": \"S3\", \"label\": \"Antith√®se\", \"short\": \"d√©sir joie possible\",\n                     \"hints\": [\"affect actif\", \"raison\", \"exemples\"],\n                     \"keywords\": [\"d√©sir\", \"joie\", \"raison\", \"affect\"]},\n                    {\"id\": \"S4\", \"label\": \"Synth√®se\", \"short\": \"d√©sir raisonn√©\",\n                     \"hints\": [\"connaissance\", \"transformation\", \"b√©atitude\"],\n                     \"keywords\": [\"raison\", \"connaissance\", \"b√©atitude\"]},\n                    {\"id\": \"S5\", \"label\": \"Conclusion\", \"short\": \"bilan\",\n                     \"hints\": [\"r√©sumer\", \"ouvrir\"],\n                     \"keywords\": [\"bilan\", \"synth√®se\"]}\n                ]\n            }\n        }\n    ],\n    \"2020\": [\n        {\n            \"sujet\": \"L'homme est-il libre ?\",\n            \"plan_id\": \"plan_homme_libre\",\n            \"plan\": {\n                \"plan_id\": \"plan_homme_libre\",\n                \"title\": \"L'homme est-il libre ?\",\n                \"philosopher\": \"spinoza\",\n                \"steps\": [\n                    {\"id\": \"S1\", \"label\": \"Intro\", \"short\": \"d√©finir libert√©\",\n                     \"hints\": [\"libert√© = ?\", \"d√©terminisme\", \"exemple\"],\n                     \"keywords\": [\"libert√©\", \"d√©terminisme\", \"d√©finition\"]},\n                    {\"id\": \"S2\", \"label\": \"Th√®se\", \"short\": \"pas libre arbitre\",\n                     \"hints\": [\"d√©terminisme\", \"causes\", \"exemples\"],\n                     \"keywords\": [\"d√©terminisme\", \"causes\", \"libre\", \"arbitre\"]},\n                    {\"id\": \"S3\", \"label\": \"Antith√®se\", \"short\": \"libert√© possible\",\n                     \"hints\": [\"connaissance\", \"n√©cessit√©\", \"exemples\"],\n                     \"keywords\": [\"libert√©\", \"connaissance\", \"n√©cessit√©\"]},\n                    {\"id\": \"S4\", \"label\": \"Synth√®se\", \"short\": \"libert√© = connaissance\",\n                     \"hints\": [\"connaissance causes\", \"transformation\", \"b√©atitude\"],\n                     \"keywords\": [\"libert√©\", \"connaissance\", \"b√©atitude\"]},\n                    {\"id\": \"S5\", \"label\": \"Conclusion\", \"short\": \"bilan\",\n                     \"hints\": [\"r√©sumer\", \"ouvrir\"],\n                     \"keywords\": [\"bilan\", \"synth√®se\"]}\n                ]\n            }\n        }\n    ]\n}\n\nclass BACSubjectPicker:\n    \"\"\"Syst√®me de piochage de sujets BAC avec plans associ√©s\"\"\"\n    \n    def __init__(self, sujets_bac: Dict = None):\n        self.sujets_bac = sujets_bac or SUJETS_BAC_SPINOZA\n        self.all_subjects = []\n        # Aplatir tous les sujets (toutes ann√©es confondues)\n        for year, subjects in self.sujets_bac.items():\n            for subject in subjects:\n                subject[\"year\"] = year\n                self.all_subjects.append(subject)\n        \n        print(f\"‚úÖ {len(self.all_subjects)} sujets BAC charg√©s (annales 2020-2024)\")\n    \n    def pick_random_subject(self) -> Dict:\n        \"\"\"Pioche un sujet BAC al√©atoire avec son plan\"\"\"\n        subject = random.choice(self.all_subjects)\n        return {\n            \"sujet\": subject[\"sujet\"],\n            \"plan_id\": subject[\"plan_id\"],\n            \"plan\": subject[\"plan\"],\n            \"year\": subject.get(\"year\", \"?\")\n        }\n    \n    def get_plan_by_id(self, plan_id: str) -> Optional[Dict]:\n        \"\"\"R√©cup√®re un plan par son ID\"\"\"\n        for subject in self.all_subjects:\n            if subject[\"plan_id\"] == plan_id:\n                return subject[\"plan\"]\n        return None\n\n# Initialiser le picker\nbac_picker = BACSubjectPicker()\n\nprint(\"‚úÖ Syst√®me de piochage BAC initialis√©\")\nprint(f\"   {len(bac_picker.all_subjects)} sujets disponibles\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. PlanTracker - Convergence vers Plan Cible\n",
    "\n",
    "**Composant qui calcule l'alignement conversationnel et guide vers le plan (selon PLAN GLOBAL.txt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PLANTRACKER - Convergence vers Plan Cible\n",
    "# ============================================================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class PlanTracker:\n",
    "    \"\"\"\n",
    "    PlanTracker : Suit l'alignement conversationnel et guide vers plan cible\n",
    "    Selon PLAN GLOBAL.txt\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, plan: Dict):\n",
    "        self.plan = plan\n",
    "        self.plan_id = plan.get(\"plan_id\", \"unknown\")\n",
    "        self.steps = plan.get(\"steps\", [])\n",
    "        \n",
    "        # Embedder pour calculer similarit√©\n",
    "        self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        \n",
    "        # Pr√©compute embeddings pour chaque step\n",
    "        self.step_embeddings = {}\n",
    "        for step in self.steps:\n",
    "            # Combiner short + hints pour embedding\n",
    "            step_text = f\"{step['short']} {' '.join(step.get('hints', [])[:2])}\"\n",
    "            self.step_embeddings[step['id']] = self.embedder.encode(\n",
    "                step_text, convert_to_tensor=True\n",
    "            )\n",
    "        \n",
    "        # √âtat de progression\n",
    "        self.current_step_idx = 0\n",
    "        self.progress_scores = {step['id']: 0.0 for step in self.steps}\n",
    "        self.completed_steps = []\n",
    "        \n",
    "        # Thresholds (selon PLAN GLOBAL.txt)\n",
    "        self.T_hint = 0.3  # Si progress < 0.3 ‚Üí hint\n",
    "        self.T_complete = 0.7  # Si progress >= 0.7 ‚Üí step compl√©t√©\n",
    "        self.alpha = 0.6  # Exponential moving average\n",
    "        \n",
    "        print(f\"‚úÖ PlanTracker initialis√© pour plan: {self.plan.get('title', '?')}\")\n",
    "        print(f\"   {len(self.steps)} √©tapes √† suivre\")\n",
    "    \n",
    "    def compute_alignment(self, utterance: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calcule l'alignement entre utterance et chaque step du plan\n",
    "        Retourne: {step_id: similarity_score}\n",
    "        \"\"\"\n",
    "        # Encoder utterance\n",
    "        utt_emb = self.embedder.encode(utterance, convert_to_tensor=True)\n",
    "        \n",
    "        # Calculer similarit√© avec chaque step\n",
    "        alignments = {}\n",
    "        for step in self.steps:\n",
    "            step_id = step['id']\n",
    "            step_emb = self.step_embeddings[step_id]\n",
    "            \n",
    "            # Cosine similarity\n",
    "            sim = util.cos_sim(utt_emb, step_emb).item()\n",
    "            alignments[step_id] = sim\n",
    "        \n",
    "        return alignments\n",
    "    \n",
    "    def update_progress(self, step_id: str, similarity: float):\n",
    "        \"\"\"\n",
    "        Met √† jour le progress_score pour un step avec exponential moving average\n",
    "        \"\"\"\n",
    "        # Normaliser similarity selon thresholds PLAN GLOBAL.txt\n",
    "        # sim_normalized = (sim - 0.45) / (0.72 - 0.45) clipped to [0,1]\n",
    "        sim_normalized = max(0.0, min(1.0, (similarity - 0.45) / (0.72 - 0.45)))\n",
    "        \n",
    "        # Exponential moving average\n",
    "        current = self.progress_scores.get(step_id, 0.0)\n",
    "        self.progress_scores[step_id] = self.alpha * current + (1 - self.alpha) * sim_normalized\n",
    "        \n",
    "        return self.progress_scores[step_id]\n",
    "    \n",
    "    def decide_action(self, utterance: str, hints_budget: int = 3) -> Dict:\n",
    "        \"\"\"\n",
    "        D√©cide quelle action prendre selon l'alignement\n",
    "        Retourne: {\n",
    "            \"action\": \"hint\" | \"continue\" | \"advance\",\n",
    "            \"current_step\": step_id,\n",
    "            \"hint\": hint_text ou None,\n",
    "            \"progress\": progress_score\n",
    "        }\n",
    "        \"\"\"\n",
    "        # Calculer alignement\n",
    "        alignments = self.compute_alignment(utterance)\n",
    "        \n",
    "        # Trouver step avec meilleur alignement\n",
    "        best_step_id = max(alignments.items(), key=lambda x: x[1])[0]\n",
    "        best_sim = alignments[best_step_id]\n",
    "        \n",
    "        # Mettre √† jour progress pour step actuel\n",
    "        current_step_id = self.steps[self.current_step_idx]['id']\n",
    "        progress = self.update_progress(current_step_id, best_sim)\n",
    "        \n",
    "        # D√©cision selon PLAN GLOBAL.txt\n",
    "        if progress >= self.T_complete:\n",
    "            # Step compl√©t√© ‚Üí avancer\n",
    "            if current_step_id not in self.completed_steps:\n",
    "                self.completed_steps.append(current_step_id)\n",
    "            if self.current_step_idx < len(self.steps) - 1:\n",
    "                self.current_step_idx += 1\n",
    "            return {\n",
    "                \"action\": \"advance\",\n",
    "                \"current_step\": self.steps[self.current_step_idx]['id'],\n",
    "                \"hint\": None,\n",
    "                \"progress\": progress,\n",
    "                \"alignment\": best_sim\n",
    "            }\n",
    "        elif progress < self.T_hint and hints_budget > 0:\n",
    "            # Progress faible ‚Üí injecter hint\n",
    "            current_step = self.steps[self.current_step_idx]\n",
    "            hints = current_step.get(\"hints\", [])\n",
    "            hint_text = hints[0] if hints else None\n",
    "            \n",
    "            return {\n",
    "                \"action\": \"hint\",\n",
    "                \"current_step\": current_step_id,\n",
    "                \"hint\": hint_text,\n",
    "                \"progress\": progress,\n",
    "                \"alignment\": best_sim,\n",
    "                \"hint_cost\": 1\n",
    "            }\n",
    "        else:\n",
    "            # Continuer sans hint\n",
    "            return {\n",
    "                \"action\": \"continue\",\n",
    "                \"current_step\": current_step_id,\n",
    "                \"hint\": None,\n",
    "                \"progress\": progress,\n",
    "                \"alignment\": best_sim\n",
    "            }\n",
    "    \n",
    "    def get_current_step(self) -> Dict:\n",
    "        \"\"\"Retourne le step actuel\"\"\"\n",
    "        return self.steps[self.current_step_idx]\n",
    "    \n",
    "    def get_progress_summary(self) -> Dict:\n",
    "        \"\"\"Retourne un r√©sum√© de la progression\"\"\"\n",
    "        total_progress = sum(self.progress_scores.values()) / len(self.steps)\n",
    "        return {\n",
    "            \"total_progress\": total_progress,\n",
    "            \"current_step\": self.steps[self.current_step_idx]['id'],\n",
    "            \"completed_steps\": len(self.completed_steps),\n",
    "            \"total_steps\": len(self.steps),\n",
    "            \"progress_by_step\": self.progress_scores.copy()\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ PlanTracker d√©fini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. V√©rification GPU & VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"GPU disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  VRAM totale: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"  VRAM libre: {torch.cuda.mem_get_info()[0] / 1024**3:.2f} GB\")\n",
    "    \n",
    "    vram_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    if vram_total < 14:\n",
    "        print(\"\\n‚ö†Ô∏è ATTENTION: VRAM < 14GB - Risque OOM avec BERT + Mistral simultan√©s\")\n",
    "        print(\"   ‚Üí Solution: Utiliser Mistral seul (option d√©sactiver BERT ci-dessous)\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ VRAM suffisante pour pipeline complet\")\n",
    "else:\n",
    "    print(\"\\n‚ùå PAS DE GPU - Activer T4 GPU dans Runtime > Change runtime type\")\n",
    "    raise RuntimeError(\"GPU requis pour ce notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload RAG Exports (ou Re-g√©n√©ration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\n# Option 1: Upload rag_exports.zip (depuis Notebook 2)\nprint(\"üì§ Option 1: Upload rag_exports.zip depuis Notebook 2\")\nprint(\"   (ou skip si vous allez r√©g√©n√©rer)\\n\")\n\nfrom google.colab import files\nuploaded = files.upload()\n\nif 'rag_exports.zip' in uploaded:\n    !unzip -q rag_exports.zip\n    RAG_DIR = \"/content/rag_exports\"  # ‚úÖ CORRIG√â: chemin correct\n    print(\"‚úÖ RAG exports charg√©s\")\nelse:\n    print(\"‚ö†Ô∏è Pas de rag_exports.zip - Vous devrez uploader les corpus et r√©g√©n√©rer\")\n    RAG_DIR = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. Prompt Syst√®me avec Plan BAC\n",
    "\n",
    "**Adaptation du prompt syst√®me pour int√©grer le sujet BAC pioch√© et guider vers le plan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PROMPT SYST√àME AVEC PLAN BAC\n",
    "# ============================================================\n",
    "\n",
    "def build_system_prompt_with_plan(subject: str, plan: Dict, current_step: Dict, hint: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Construit le prompt syst√®me selon PLAN GLOBAL.txt\n",
    "    Int√®gre le sujet BAC, le plan, l'√©tape actuelle et optionnellement un hint\n",
    "    \"\"\"\n",
    "    plan_title = plan.get(\"title\", \"?\")\n",
    "    step_label = current_step.get(\"label\", \"?\")\n",
    "    step_short = current_step.get(\"short\", \"?\")\n",
    "    \n",
    "    base_prompt = f\"\"\"Tu es \"Spinoza Secours\", examinateur chaleureux, niveau Terminale. Tu aides l'√©l√®ve √† construire un plan en 7-15 √©changes.\n",
    "\n",
    "SUJET BAC: {subject}\n",
    "\n",
    "PLAN CIBLE: {plan_title}\n",
    "√âTAPE ACTUELLE: {step_label} ‚Äî {step_short}\n",
    "\n",
    "TES INSTRUCTIONS:\n",
    "- Reformule bri√®vement ce que l'√©l√®ve dit\n",
    "- Corrige si erreur conceptuelle\n",
    "- Pose une question qui aide √† avancer vers l'√©tape suivante du plan\n",
    "- Ne jamais citer d'autres doctrines (reste sur Spinoza)\n",
    "- R√©ponses courtes (2-4 phrases max)\n",
    "\"\"\"\n",
    "    \n",
    "    # Ajouter hint si disponible (selon PLAN GLOBAL.txt)\n",
    "    if hint:\n",
    "        base_prompt += f\"\"\"\n",
    "HINT √Ä INT√âGRER SUBTILEMENT: {hint}\n",
    "‚Üí Int√®gre ce hint dans ta question mais ne donne pas la r√©ponse compl√®te.\n",
    "‚Üí Co√ªt hint: -5 points (gamification)\n",
    "\"\"\"\n",
    "    \n",
    "    # Ajouter directive pour √©tape suivante\n",
    "    steps = plan.get(\"steps\", [])\n",
    "    current_idx = next((i for i, s in enumerate(steps) if s[\"id\"] == current_step[\"id\"]), 0)\n",
    "    if current_idx < len(steps) - 1:\n",
    "        next_step = steps[current_idx + 1]\n",
    "        base_prompt += f\"\"\"\n",
    "OBJECTIF: Aide l'√©l√®ve √† progresser vers l'√©tape suivante: {next_step['label']} ‚Äî {next_step['short']}\n",
    "\"\"\"\n",
    "    \n",
    "    return base_prompt\n",
    "\n",
    "print(\"‚úÖ Fonction build_system_prompt_with_plan d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. Pipeline TRM avec Plan BAC et PlanTracker\n",
    "\n",
    "**Version adapt√©e du pipeline qui int√®gre le piochage de sujet BAC et la convergence vers le plan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PIPELINE TRM AVEC PLAN BAC + PLANTRACKER\n",
    "# ============================================================\n",
    "\n",
    "class TRMPipelineWithPlan:\n",
    "    \"\"\"\n",
    "    Pipeline TRM complet avec syst√®me de piochage BAC et PlanTracker\n",
    "    Selon PLAN GLOBAL.txt\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rag, bert, mistral, bac_picker: BACSubjectPicker):\n",
    "        self.rag = rag\n",
    "        self.bert = bert\n",
    "        self.mistral = mistral\n",
    "        self.bac_picker = bac_picker\n",
    "        \n",
    "        # √âtat conversation\n",
    "        self.conversation_history = []\n",
    "        self.state_image = None\n",
    "        \n",
    "        # Plan BAC actuel\n",
    "        self.current_subject = None\n",
    "        self.current_plan = None\n",
    "        self.plan_tracker = None\n",
    "        self.hints_budget = 3  # Budget initial de hints\n",
    "        \n",
    "        print(\"‚úÖ TRMPipelineWithPlan initialis√©\")\n",
    "    \n",
    "    def start_new_session(self) -> Dict:\n",
    "        \"\"\"\n",
    "        D√©marre une nouvelle session avec un sujet BAC pioch√© al√©atoirement\n",
    "        Retourne: {\"sujet\": str, \"plan\": Dict, \"year\": str}\n",
    "        \"\"\"\n",
    "        # Piocher sujet BAC\n",
    "        subject_data = self.bac_picker.pick_random_subject()\n",
    "        self.current_subject = subject_data[\"sujet\"]\n",
    "        self.current_plan = subject_data[\"plan\"]\n",
    "        \n",
    "        # Initialiser PlanTracker\n",
    "        self.plan_tracker = PlanTracker(self.current_plan)\n",
    "        \n",
    "        # R√©initialiser conversation\n",
    "        self.conversation_history = []\n",
    "        self.state_image = None\n",
    "        self.hints_budget = 3\n",
    "        \n",
    "        print(f\"\\\\nüé≤ Nouveau sujet BAC pioch√© ({subject_data.get('year', '?')}):\")\n",
    "        print(f\"   {self.current_subject}\")\n",
    "        print(f\"   Plan: {self.current_plan.get('title', '?')}\")\n",
    "        \n",
    "        return subject_data\n",
    "    \n",
    "    def chat(self, user_input: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Dialogue complet TRM avec plan tracking\n",
    "        Retourne: {\n",
    "            \"response\": str,\n",
    "            \"progress\": Dict,\n",
    "            \"hint_used\": bool,\n",
    "            \"current_step\": str\n",
    "        }\n",
    "        \"\"\"\n",
    "        if not self.plan_tracker:\n",
    "            # Si pas de session d√©marr√©e, d√©marrer automatiquement\n",
    "            self.start_new_session()\n",
    "        \n",
    "        # 1. PlanTracker: Calculer alignement et d√©cider action\n",
    "        action = self.plan_tracker.decide_action(user_input, self.hints_budget)\n",
    "        current_step = self.plan_tracker.get_current_step()\n",
    "        \n",
    "        # 2. RAG Retrieve (avec contexte step actuel)\n",
    "        if self.rag:\n",
    "            # Enrichir query avec keywords du step actuel\n",
    "            step_keywords = \" \".join(current_step.get(\"keywords\", []))\n",
    "            enriched_query = f\"{user_input} {step_keywords}\"\n",
    "            rag_passages = self.rag.retrieve(enriched_query, top_k=3)\n",
    "            print(f\"üìö RAG: {len(rag_passages)} passages r√©cup√©r√©s\")\n",
    "        else:\n",
    "            rag_passages = []\n",
    "        \n",
    "        # 3. BERT Encode STATE_IMAGE avec contexte plan\n",
    "        if self.bert:\n",
    "            self.conversation_history.append({\"user\": user_input, \"assistant\": \"\"})\n",
    "            \n",
    "            plan_context = {\n",
    "                \"current_step\": action[\"current_step\"],\n",
    "                \"plan\": self.current_plan,\n",
    "                \"progress\": action[\"progress\"]\n",
    "            }\n",
    "            \n",
    "            self.state_image = self.bert.encode_to_state_image(\n",
    "                self.conversation_history,\n",
    "                rag_passages,\n",
    "                self.state_image,\n",
    "                {},\n",
    "                plan_context=plan_context  # Nouveau param√®tre\n",
    "            )\n",
    "            print(f\"üß† STATE: {len(self.state_image['concepts_actifs'])} concepts actifs\")\n",
    "        else:\n",
    "            # STATE simplifi√© sans BERT\n",
    "            self.state_image = {\n",
    "                \"concepts_actifs\": [],\n",
    "                \"concepts_rag\": [c for p in rag_passages for c in p.get(\"concepts\", [])[:2]],\n",
    "                \"intention\": \"question\",\n",
    "                \"style\": \"standard\",\n",
    "                \"plan_context\": {\n",
    "                    \"current_step\": action[\"current_step\"],\n",
    "                    \"current_step_short\": current_step.get(\"short\", \"?\")\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # 4. Construire prompt syst√®me avec plan\n",
    "        hint_text = action.get(\"hint\") if action[\"action\"] == \"hint\" else None\n",
    "        system_prompt = build_system_prompt_with_plan(\n",
    "            self.current_subject,\n",
    "            self.current_plan,\n",
    "            current_step,\n",
    "            hint_text\n",
    "        )\n",
    "        \n",
    "        # 5. Mistral Generate\n",
    "        response = self.mistral.generate(\n",
    "            self.state_image,\n",
    "            user_input,\n",
    "            system_prompt\n",
    "        )\n",
    "        \n",
    "        # 6. Mettre √† jour historique\n",
    "        if self.conversation_history:\n",
    "            self.conversation_history[-1][\"assistant\"] = response\n",
    "        \n",
    "        # 7. G√©rer budget hints\n",
    "        hint_used = False\n",
    "        if action[\"action\"] == \"hint\" and action.get(\"hint_cost\", 0) > 0:\n",
    "            self.hints_budget -= action[\"hint_cost\"]\n",
    "            hint_used = True\n",
    "        \n",
    "        # 8. R√©cup√©rer r√©sum√© progression\n",
    "        progress_summary = self.plan_tracker.get_progress_summary()\n",
    "        \n",
    "        return {\n",
    "            \"response\": response,\n",
    "            \"progress\": progress_summary,\n",
    "            \"hint_used\": hint_used,\n",
    "            \"hints_remaining\": self.hints_budget,\n",
    "            \"current_step\": action[\"current_step\"],\n",
    "            \"action\": action[\"action\"]\n",
    "        }\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"R√©initialise la conversation\"\"\"\n",
    "        self.conversation_history = []\n",
    "        self.state_image = None\n",
    "        self.plan_tracker = None\n",
    "        self.current_subject = None\n",
    "        self.current_plan = None\n",
    "        self.hints_budget = 3\n",
    "        print(\"üîÑ Conversation r√©initialis√©e\")\n",
    "\n",
    "print(\"‚úÖ TRMPipelineWithPlan d√©fini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6. Initialisation Pipeline avec Plan BAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser pipeline avec plan BAC\n",
    "pipeline_with_plan = TRMPipelineWithPlan(rag, bert, mistral, bac_picker)\n",
    "\n",
    "# D√©marrer une session avec sujet BAC pioch√©\n",
    "session_data = pipeline_with_plan.start_new_session()\n",
    "\n",
    "print(f\"\\\\n‚úÖ Pipeline TRM avec Plan BAC initialis√©\")\n",
    "print(f\"   Sujet: {session_data['sujet']}\")\n",
    "print(f\"   Plan: {session_data['plan']['title']}\")\n",
    "print(f\"   Ann√©e: {session_data.get('year', '?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5. Interface Gradio avec Plan BAC\n",
    "\n",
    "**Interface adapt√©e pour afficher le sujet BAC, la progression vers le plan et les hints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chat_with_plan(user_input, history, subject_info):\n",
    "    \"\"\"Interface Gradio pour dialogue avec plan BAC\"\"\"\n",
    "    if not user_input.strip():\n",
    "        return history, history, subject_info\n",
    "    \n",
    "    # G√©n√©rer r√©ponse avec plan tracking\n",
    "    result = pipeline_with_plan.chat(user_input)\n",
    "    \n",
    "    # Construire message avec info progression\n",
    "    response = result[\"response\"]\n",
    "    progress = result[\"progress\"]\n",
    "    current_step = result[\"current_step\"]\n",
    "    \n",
    "    # Ajouter info progression dans r√©ponse\n",
    "    progress_text = f\"\\\\n\\\\nüìä Progression: {progress['completed_steps']}/{progress['total_steps']} √©tapes | \"\n",
    "    progress_text += f\"√âtape actuelle: {current_step} | \"\n",
    "    progress_text += f\"Hints restants: {result['hints_remaining']}\"\n",
    "    \n",
    "    if result[\"hint_used\"]:\n",
    "        progress_text += \" ‚ö†Ô∏è (Hint utilis√©: -5 points)\"\n",
    "    \n",
    "    full_response = response + progress_text\n",
    "    \n",
    "    # Mettre √† jour historique\n",
    "    history.append((user_input, full_response))\n",
    "    \n",
    "    # Mettre √† jour info sujet\n",
    "    if pipeline_with_plan.current_subject:\n",
    "        subject_info = f\"\"\"\n",
    "**üé≤ Sujet BAC:** {pipeline_with_plan.current_subject}\n",
    "**üìã Plan:** {pipeline_with_plan.current_plan.get('title', '?')}\n",
    "**üìç √âtape actuelle:** {current_step}\n",
    "**üìä Progression globale:** {progress['total_progress']:.1%}\n",
    "\"\"\"\n",
    "    \n",
    "    return history, history, subject_info\n",
    "\n",
    "def start_new_session():\n",
    "    \"\"\"D√©marre une nouvelle session avec nouveau sujet BAC\"\"\"\n",
    "    session_data = pipeline_with_plan.start_new_session()\n",
    "    \n",
    "    subject_info = f\"\"\"\n",
    "**üé≤ Sujet BAC:** {session_data['sujet']}\n",
    "**üìã Plan:** {session_data['plan']['title']}\n",
    "**üìÖ Ann√©e:** {session_data.get('year', '?')}\n",
    "**üìç √âtape actuelle:** S1 (Intro)\n",
    "**üìä Progression:** 0%\n",
    "**üí° Hints disponibles:** 3\n",
    "\"\"\"\n",
    "    \n",
    "    return [], [], subject_info\n",
    "\n",
    "# Interface Gradio\n",
    "with gr.Blocks(title=\"TRM POC - Dialogue Spinoza avec Plan BAC\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # üßô Dialogue avec Spinoza (TRM POC + Plan BAC)\n",
    "        \n",
    "        **Architecture TRM:** RAG + BERT + Mistral 7B + PlanTracker\n",
    "        \n",
    "        Le syst√®me pioche un sujet BAC al√©atoirement et guide la conversation vers le plan cible.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            chatbot = gr.Chatbot(\n",
    "                label=\"Conversation avec Spinoza\",\n",
    "                height=400\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                user_input = gr.Textbox(\n",
    "                    label=\"Votre r√©ponse\",\n",
    "                    placeholder=\"R√©pondez au sujet BAC...\",\n",
    "                    scale=4\n",
    "                )\n",
    "                submit_btn = gr.Button(\"Envoyer\", scale=1)\n",
    "            \n",
    "            with gr.Row():\n",
    "                new_session_btn = gr.Button(\"üé≤ Nouveau sujet BAC\", variant=\"primary\")\n",
    "                clear_btn = gr.Button(\"R√©initialiser\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            subject_display = gr.Markdown(\n",
    "                label=\"üìã Informations Sujet BAC\",\n",
    "                value=\"Cliquez sur 'Nouveau sujet BAC' pour commencer\"\n",
    "            )\n",
    "    \n",
    "    # √âtat historique\n",
    "    history_state = gr.State([])\n",
    "    \n",
    "    # Actions\n",
    "    submit_btn.click(\n",
    "        chat_with_plan,\n",
    "        inputs=[user_input, history_state, subject_display],\n",
    "        outputs=[chatbot, history_state, subject_display]\n",
    "    )\n",
    "    \n",
    "    user_input.submit(\n",
    "        chat_with_plan,\n",
    "        inputs=[user_input, history_state, subject_display],\n",
    "        outputs=[chatbot, history_state, subject_display]\n",
    "    )\n",
    "    \n",
    "    new_session_btn.click(\n",
    "        start_new_session,\n",
    "        outputs=[chatbot, history_state, subject_display]\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(\n",
    "        lambda: ([], [], \"Conversation r√©initialis√©e\"),\n",
    "        outputs=[chatbot, history_state, subject_display]\n",
    "    )\n",
    "\n",
    "# Lancer interface\n",
    "demo.launch(share=True, debug=True)\n",
    "\n",
    "print(\"\\\\nüöÄ Interface Gradio avec Plan BAC lanc√©e !\")\n",
    "print(\"   Cliquez sur 'Nouveau sujet BAC' pour d√©marrer une session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù R√©sum√© des Modifications\n",
    "\n",
    "### ‚úÖ Nouveaux Composants Ajout√©s\n",
    "\n",
    "1. **Syst√®me de Piochage BAC (`BACSubjectPicker`)**\n",
    "   - Pioche al√©atoirement un sujet parmi les annales des 5 derni√®res ann√©es\n",
    "   - Charge le plan associ√© au sujet\n",
    "   - Format JSON conforme √† PLAN GLOBAL.txt\n",
    "\n",
    "2. **PlanTracker**\n",
    "   - Calcule l'alignement conversationnel avec chaque √©tape du plan\n",
    "   - Utilise embeddings (sentence-transformers) pour similarit√© cosinus\n",
    "   - D√©cide des actions: hint, continue, advance\n",
    "   - Suit la progression avec exponential moving average\n",
    "\n",
    "3. **Prompt Syst√®me Adapt√© (`build_system_prompt_with_plan`)**\n",
    "   - Int√®gre le sujet BAC pioch√©\n",
    "   - Indique l'√©tape actuelle du plan\n",
    "   - Injecte subtilement les hints si n√©cessaire\n",
    "   - Guide vers l'√©tape suivante\n",
    "\n",
    "4. **Pipeline TRM avec Plan (`TRMPipelineWithPlan`)**\n",
    "   - Int√®gre le piochage BAC et PlanTracker\n",
    "   - Met √† jour le STATE_IMAGE avec contexte plan\n",
    "   - G√®re le budget de hints (3 par session)\n",
    "   - Retourne progression et m√©triques\n",
    "\n",
    "5. **Interface Gradio Adapt√©e**\n",
    "   - Affiche le sujet BAC pioch√©\n",
    "   - Montre la progression vers le plan\n",
    "   - Indique les hints restants\n",
    "   - Bouton pour d√©marrer nouvelle session\n",
    "\n",
    "### üéØ Fonctionnalit√©s\n",
    "\n",
    "- ‚úÖ Piochage al√©atoire de sujets BAC (5 derni√®res ann√©es)\n",
    "- ‚úÖ Chargement automatique du plan associ√©\n",
    "- ‚úÖ Calcul d'alignement conversationnel avec plan\n",
    "- ‚úÖ Injection intelligente de hints selon progression\n",
    "- ‚úÖ Suivi de progression √©tape par √©tape\n",
    "- ‚úÖ Interface utilisateur avec feedback visuel\n",
    "\n",
    "### üìä Conformit√© PLAN GLOBAL.txt\n",
    "\n",
    "- ‚úÖ Format plan JSON (plan_id, steps avec hints)\n",
    "- ‚úÖ Mesure d'alignement par embedding similarity\n",
    "- ‚úÖ Thresholds: T_hint=0.3, T_complete=0.7\n",
    "- ‚úÖ Exponential moving average pour progress_score\n",
    "- ‚úÖ Gestion budget hints (gamification)\n",
    "- ‚úÖ Prompt syst√®me avec directive vers √©tape suivante\n",
    "\n",
    "### ‚ö†Ô∏è Action Requise\n",
    "\n",
    "**Modifier la m√©thode `encode_to_state_image` du BERTEncoder** pour accepter `plan_context` (voir note ci-dessus).\n",
    "\n",
    "---\n",
    "\n",
    "**üí∞ Co√ªt:** 0‚Ç¨ (Colab gratuit GPU T4)\n",
    "\n",
    "**‚è±Ô∏è Temps:** ~3-4h (chargement + dialogue)\n",
    "\n",
    "**üéØ Objectif:** Dialogue TRM avec guidage vers plan BAC ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classes R√©utilis√©es (Notebooks 1-2-3)\n",
    "\n",
    "Code copi√© depuis les notebooks pr√©c√©dents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# BERT ENCODER (depuis Notebook 1) - ‚úÖ MODIFI√â POUR PLAN_CONTEXT\n# ============================================================\n\nfrom transformers import AutoTokenizer, AutoModel\nimport spacy\nimport json\nimport re\nfrom typing import List, Dict, Optional\nfrom collections import Counter\n\nnlp = spacy.load(\"fr_core_news_sm\")\n\nclass BERTEncoder:\n    \"\"\"Encodeur BERT pour STATE_IMAGE\"\"\"\n    \n    def __init__(self, model_name: str = \"camembert-base\"):\n        print(f\"‚è≥ Chargement BERT {model_name}...\")\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModel.from_pretrained(model_name)\n        self.model.eval()\n        print(\"‚úÖ BERT charg√© (CPU)\")\n    \n    def extract_keywords(self, text: str, top_k: int = 5) -> List[str]:\n        doc = nlp(text)\n        entities = [ent.text.lower() for ent in doc.ents]\n        nouns = [token.text.lower() for token in doc \n                 if token.pos_ in [\"NOUN\", \"PROPN\"] and len(token.text) > 3]\n        all_keywords = entities + nouns\n        counter = Counter(all_keywords)\n        return [word for word, count in counter.most_common(top_k)]\n    \n    def extract_concepts_from_rag(self, rag_passages: List[Dict]) -> List[str]:\n        concepts = []\n        for passage in rag_passages:\n            if passage.get(\"concepts\"):\n                concepts.extend(passage[\"concepts\"][:3])\n            else:\n                text = passage.get(\"text\", \"\")\n                keywords = self.extract_keywords(text, top_k=3)\n                concepts.extend(keywords)\n        unique_concepts = list(dict.fromkeys(concepts))\n        return unique_concepts[:8]\n    \n    def analyze_intention(self, text: str) -> str:\n        text_lower = text.lower()\n        if any(m in text_lower for m in [\"?\", \"comment\", \"pourquoi\", \"qu'est-ce\"]):\n            return \"question\"\n        elif any(m in text_lower for m in [\"explique\", \"clarifie\", \"pr√©cise\"]):\n            return \"clarification\"\n        elif any(m in text_lower for m in [\"d'accord\", \"ok\", \"compris\", \"oui\"]):\n            return \"accord\"\n        elif any(m in text_lower for m in [\"non\", \"mais\", \"pas d'accord\", \"faux\"]):\n            return \"d√©saccord\"\n        return \"neutre\"\n    \n    def analyze_tension(self, text: str) -> str:\n        text_lower = text.lower()\n        if any(m in text_lower for m in [\"mais\", \"pourtant\", \"cependant\"]):\n            return \"opposition\"\n        elif any(m in text_lower for m in [\"comprends pas\", \"chelou\", \"bizarre\"]):\n            return \"confusion\"\n        return \"neutre\"\n    \n    def analyze_style(self, text: str) -> str:\n        text_lower = text.lower()\n        word_count = len(text.split())\n        if word_count < 10:\n            return \"concis\"\n        elif any(m in text_lower for m in [\"exemple\", \"concr√®tement\", \"genre\"]):\n            return \"p√©dagogique\"\n        return \"standard\"\n    \n    def encode_to_state_image(\n        self,\n        conversation: List[Dict],\n        rag_passages: List[Dict],\n        prev_state: Optional[Dict] = None,\n        mini_store_feedback: Optional[Dict] = None,\n        plan_context: Optional[Dict] = None  # ‚úÖ AJOUT√â\n    ) -> Dict:\n        last_exchange = conversation[-1] if conversation else {}\n        user_text = last_exchange.get(\"user\", \"\")\n        assistant_text = last_exchange.get(\"assistant\", \"\")\n        \n        concepts_actifs = self.extract_keywords(user_text + \" \" + assistant_text, top_k=5)\n        concepts_rag = self.extract_concepts_from_rag(rag_passages)\n        sources_rag = [p.get(\"source\", \"?\") for p in rag_passages]\n        \n        # ‚úÖ AJOUT√â: Int√©grer contexte plan si disponible\n        plan_info = {}\n        if plan_context:\n            current_step = plan_context.get(\"current_step\")\n            plan = plan_context.get(\"plan\", {})\n            progress = plan_context.get(\"progress\", 0.0)\n            \n            if current_step and plan:\n                step_obj = next((s for s in plan.get(\"steps\", []) if s[\"id\"] == current_step), None)\n                if step_obj:\n                    plan_info = {\n                        \"plan_id\": plan.get(\"plan_id\"),\n                        \"current_step\": current_step,\n                        \"current_step_label\": step_obj.get(\"label\"),\n                        \"current_step_short\": step_obj.get(\"short\"),\n                        \"progress_score\": progress,\n                        \"plan_hints\": step_obj.get(\"hints\", [])[:2]\n                    }\n        \n        return {\n            \"concepts_actifs\": concepts_actifs,\n            \"concepts_rag\": concepts_rag,\n            \"sources_rag\": sources_rag,\n            \"intention\": self.analyze_intention(user_text),\n            \"tension\": self.analyze_tension(user_text),\n            \"style\": self.analyze_style(user_text),\n            \"ton\": \"bienveillant\",\n            \"priorite\": [\"concepts_actifs\", \"intention\"],\n            \"relations\": [],\n            \"emotion\": \"curieux\",\n            \"recurrence\": mini_store_feedback.get(\"recurrences\", {}) if mini_store_feedback else {},\n            \"plan_context\": plan_info,  # ‚úÖ AJOUT√â\n            \"metadata\": {\n                \"philosopher\": rag_passages[0].get(\"philosopher\", \"?\") if rag_passages else None,\n                \"turn\": (prev_state.get(\"metadata\", {}).get(\"turn\", 0) + 1) if prev_state else 1\n            }\n        }\n\nprint(\"‚úÖ BERTEncoder d√©fini avec support plan_context\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RAG RETRIEVER (depuis Notebook 2)\n",
    "# ============================================================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "class RAGRetriever:\n",
    "    \"\"\"RAG Retriever avec FAISS\"\"\"\n",
    "    \n",
    "    def __init__(self, rag_dir: str, philosopher: str = \"spinoza\"):\n",
    "        print(f\"‚è≥ Chargement RAG pour {philosopher}...\")\n",
    "        self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.philosopher = philosopher\n",
    "        \n",
    "        # Charger index FAISS\n",
    "        index_path = f\"{rag_dir}/{philosopher}_faiss.index\"\n",
    "        self.index = faiss.read_index(index_path)\n",
    "        \n",
    "        # Charger passages\n",
    "        passages_path = f\"{rag_dir}/{philosopher}_passages.pkl\"\n",
    "        with open(passages_path, 'rb') as f:\n",
    "            self.passages = pickle.load(f)\n",
    "        \n",
    "        print(f\"‚úÖ RAG charg√©: {len(self.passages)} passages index√©s\")\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        # Encoder query\n",
    "        query_emb = self.embedder.encode([query], convert_to_numpy=True)\n",
    "        faiss.normalize_L2(query_emb)\n",
    "        \n",
    "        # Recherche\n",
    "        scores, indices = self.index.search(query_emb, top_k)\n",
    "        \n",
    "        # Filtrer par threshold\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], indices[0]):\n",
    "            if score >= 0.45:  # Threshold\n",
    "                passage = self.passages[idx].copy()\n",
    "                passage[\"similarity_score\"] = float(score)\n",
    "                results.append(passage)\n",
    "        \n",
    "        return results[:top_k]\n",
    "\n",
    "print(\"‚úÖ RAGRetriever d√©fini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MISTRAL GENERATOR (depuis Notebook 3)\n",
    "# ============================================================\n",
    "\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import time\n",
    "\n",
    "class MistralGenerator:\n",
    "    \"\"\"G√©n√©rateur Mistral 7B\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"mistralai/Mistral-7B-Instruct-v0.2\"):\n",
    "        print(f\"‚è≥ Chargement Mistral {model_name} (4-bit)...\")\n",
    "        print(\"‚ö†Ô∏è Cela peut prendre 5-10 minutes...\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        quant_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_use_double_quant=True\n",
    "        )\n",
    "        \n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=quant_config,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Mistral charg√© (GPU)\")\n",
    "    \n",
    "    def format_state_image(self, state_image: Dict) -> str:\n",
    "        lines = []\n",
    "        if state_image.get(\"concepts_actifs\"):\n",
    "            lines.append(f\"Concepts actifs: {', '.join(state_image['concepts_actifs'][:5])}\")\n",
    "        if state_image.get(\"concepts_rag\"):\n",
    "            lines.append(f\"Concepts corpus: {', '.join(state_image['concepts_rag'][:5])}\")\n",
    "        if state_image.get(\"intention\"):\n",
    "            lines.append(f\"Intention: {state_image['intention']}\")\n",
    "        if state_image.get(\"style\"):\n",
    "            lines.append(f\"Style: {state_image['style']}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def generate(\n",
    "        self,\n",
    "        state_image: Dict,\n",
    "        user_input: str,\n",
    "        system_prompt: str,\n",
    "        max_new_tokens: int = 300\n",
    "    ) -> str:\n",
    "        state_text = self.format_state_image(state_image)\n",
    "        \n",
    "        prompt = f\"\"\"<s>[INST] {system_prompt}\n",
    "\n",
    "[CONTEXT_STATE]\n",
    "{state_text}\n",
    "\n",
    "[USER_INPUT]\n",
    "{user_input}\n",
    "\n",
    "R√©ponds en incarnant le philosophe. [/INST]\"\"\"\n",
    "        \n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        response = self.tokenizer.decode(\n",
    "            outputs[0][inputs['input_ids'].shape[1]:], \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "\n",
    "print(\"‚úÖ MistralGenerator d√©fini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chargement Pipeline Complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "USE_BERT = True  # Mettre False si VRAM insuffisante\n",
    "PHILOSOPHER = \"spinoza\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ CHARGEMENT PIPELINE TRM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. RAG Retriever\n",
    "if RAG_DIR and os.path.exists(f\"{RAG_DIR}/{PHILOSOPHER}_faiss.index\"):\n",
    "    rag = RAGRetriever(RAG_DIR, PHILOSOPHER)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è RAG non disponible - Utiliser Notebook 2 d'abord\")\n",
    "    rag = None\n",
    "\n",
    "# 2. BERT Encoder (optionnel si VRAM limit√©e)\n",
    "if USE_BERT:\n",
    "    bert = BERTEncoder()\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è BERT d√©sactiv√© - STATE_IMAGE simplifi√©\")\n",
    "    bert = None\n",
    "\n",
    "# 3. Mistral Generator\n",
    "mistral = MistralGenerator()\n",
    "\n",
    "# V√©rifier VRAM apr√®s chargement\n",
    "vram_used = (torch.cuda.mem_get_info()[1] - torch.cuda.mem_get_info()[0]) / 1024**3\n",
    "print(f\"\\nüìä VRAM utilis√©e: {vram_used:.2f} GB / {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline TRM pr√™t !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prompt Syst√®me Spinoza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_SPINOZA = \"\"\"Tu ES Spinoza incarn√©. Tu dialogues avec un √©l√®ve de Terminale en premi√®re personne.\n",
    "\n",
    "TON STYLE :\n",
    "- G√©om√©trie des affects : tu r√©v√®les les causes n√©cessaires, tu d√©duis\n",
    "- Tu enseignes que Dieu = Nature\n",
    "- Ton vocabulaire : conatus, affects, puissance d'agir, b√©atitude\n",
    "\n",
    "TES SCH√àMES LOGIQUES :\n",
    "- Dieu = Nature = Substance unique\n",
    "- Libert√© = Connaissance de la n√©cessit√©\n",
    "- Si joie ‚Üí augmentation puissance\n",
    "- Causalit√© : Tout a une cause (pas de libre arbitre)\n",
    "\n",
    "TA M√âTHODE :\n",
    "1. Tu r√©v√®les la n√©cessit√© causale\n",
    "2. Tu distingues servitude (ignorance) vs libert√© (connaissance)\n",
    "3. Tu utilises des exemples concrets modernes (r√©seaux sociaux, affects quotidiens)\n",
    "\n",
    "FORMULES DIALECTIQUES :\n",
    "- \"MAIS ALORS, as-tu conscience des CAUSES de tes choix ?\"\n",
    "- \"Si tu ignores les causes, alors tu crois √™tre libre (mais tu te trompes)\"\n",
    "- \"Attends. Tu dis X mais tu fais Y. Comment tu expliques ?\"\n",
    "\n",
    "R√©ponds en 2-4 phrases maximum, de mani√®re p√©dagogique et bienveillante.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline TRM Complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRMPipeline:\n",
    "    \"\"\"Pipeline TRM complet : RAG ‚Üí BERT ‚Üí Mistral\"\"\"\n",
    "    \n",
    "    def __init__(self, rag, bert, mistral, system_prompt):\n",
    "        self.rag = rag\n",
    "        self.bert = bert\n",
    "        self.mistral = mistral\n",
    "        self.system_prompt = system_prompt\n",
    "        \n",
    "        # √âtat conversation\n",
    "        self.conversation_history = []\n",
    "        self.state_image = None\n",
    "    \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"Dialogue complet TRM\"\"\"\n",
    "        \n",
    "        # 1. RAG Retrieve\n",
    "        if self.rag:\n",
    "            rag_passages = self.rag.retrieve(user_input, top_k=3)\n",
    "            print(f\"üìö RAG: {len(rag_passages)} passages r√©cup√©r√©s\")\n",
    "        else:\n",
    "            rag_passages = []\n",
    "        \n",
    "        # 2. BERT Encode STATE_IMAGE\n",
    "        if self.bert:\n",
    "            # Ajouter dernier √©change\n",
    "            self.conversation_history.append({\"user\": user_input, \"assistant\": \"\"})\n",
    "            \n",
    "            self.state_image = self.bert.encode_to_state_image(\n",
    "                self.conversation_history,\n",
    "                rag_passages,\n",
    "                self.state_image,\n",
    "                {}\n",
    "            )\n",
    "            print(f\"üß† STATE: {len(self.state_image['concepts_actifs'])} concepts actifs\")\n",
    "        else:\n",
    "            # STATE simplifi√© sans BERT\n",
    "            self.state_image = {\n",
    "                \"concepts_actifs\": [],\n",
    "                \"concepts_rag\": [c for p in rag_passages for c in p.get(\"concepts\", [])[:2]],\n",
    "                \"intention\": \"question\",\n",
    "                \"style\": \"standard\"\n",
    "            }\n",
    "        \n",
    "        # 3. Mistral Generate\n",
    "        response = self.mistral.generate(\n",
    "            self.state_image,\n",
    "            user_input,\n",
    "            self.system_prompt\n",
    "        )\n",
    "        \n",
    "        # Mettre √† jour historique\n",
    "        if self.conversation_history:\n",
    "            self.conversation_history[-1][\"assistant\"] = response\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"R√©initialise la conversation\"\"\"\n",
    "        self.conversation_history = []\n",
    "        self.state_image = None\n",
    "        print(\"üîÑ Conversation r√©initialis√©e\")\n",
    "\n",
    "# Initialiser pipeline\n",
    "pipeline = TRMPipeline(rag, bert, mistral, SYSTEM_PROMPT_SPINOZA)\n",
    "\n",
    "print(\"‚úÖ Pipeline TRM initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Dialogue Manuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test simple\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí¨ TEST DIALOGUE SPINOZA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "query = \"C'est quoi le conatus ?\"\n",
    "print(f\"\\nüë§ Utilisateur: {query}\")\n",
    "\n",
    "response = pipeline.chat(query)\n",
    "print(f\"\\nüßô Spinoza: {response}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interface Gradio Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chat_interface(user_input, history):\n",
    "    \"\"\"Interface Gradio pour dialogue\"\"\"\n",
    "    if not user_input.strip():\n",
    "        return history, history\n",
    "    \n",
    "    # G√©n√©rer r√©ponse\n",
    "    response = pipeline.chat(user_input)\n",
    "    \n",
    "    # Mettre √† jour historique\n",
    "    history.append((user_input, response))\n",
    "    \n",
    "    return history, history\n",
    "\n",
    "def reset_conversation():\n",
    "    \"\"\"R√©initialise la conversation\"\"\"\n",
    "    pipeline.reset()\n",
    "    return [], []\n",
    "\n",
    "# Interface Gradio\n",
    "with gr.Blocks(title=\"TRM POC - Dialogue Spinoza\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # üßô Dialogue avec Spinoza (TRM POC)\n",
    "        \n",
    "        **Architecture TRM:** RAG + BERT + Mistral 7B\n",
    "        \n",
    "        Posez vos questions sur le conatus, les affects, la libert√©, etc.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"Conversation avec Spinoza\",\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(\n",
    "            label=\"Votre question\",\n",
    "            placeholder=\"Ex: C'est quoi le conatus ?\",\n",
    "            scale=4\n",
    "        )\n",
    "        submit_btn = gr.Button(\"Envoyer\", scale=1)\n",
    "    \n",
    "    with gr.Row():\n",
    "        clear_btn = gr.Button(\"R√©initialiser conversation\")\n",
    "    \n",
    "    # √âtat historique\n",
    "    history_state = gr.State([])\n",
    "    \n",
    "    # Actions\n",
    "    submit_btn.click(\n",
    "        chat_interface,\n",
    "        inputs=[user_input, history_state],\n",
    "        outputs=[chatbot, history_state]\n",
    "    )\n",
    "    \n",
    "    user_input.submit(\n",
    "        chat_interface,\n",
    "        inputs=[user_input, history_state],\n",
    "        outputs=[chatbot, history_state]\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(\n",
    "        reset_conversation,\n",
    "        outputs=[chatbot, history_state]\n",
    "    )\n",
    "\n",
    "# Lancer interface\n",
    "demo.launch(share=True, debug=True)\n",
    "\n",
    "print(\"\\nüöÄ Interface Gradio lanc√©e !\")\n",
    "print(\"   Cliquez sur le lien 'public URL' pour dialoguer avec Spinoza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù R√©sum√©\n",
    "\n",
    "### ‚úÖ Impl√©ment√©\n",
    "- ‚úÖ Pipeline TRM complet (RAG + BERT + Mistral)\n",
    "- ‚úÖ Interface dialogue interactive Gradio\n",
    "- ‚úÖ Gestion conversation avec STATE_IMAGE\n",
    "- ‚úÖ Tests end-to-end Spinoza\n",
    "\n",
    "### üéØ Validation POC\n",
    "- ‚úÖ Dialogue fonctionnel avec Spinoza\n",
    "- ‚úÖ RAG retrieve passages pertinents\n",
    "- ‚úÖ BERT g√©n√®re STATE_IMAGE condens√©\n",
    "- ‚úÖ Mistral r√©pond avec contexte ‚â§500 tokens\n",
    "\n",
    "### ‚ö†Ô∏è Limitations Colab Gratuit\n",
    "- **VRAM T4 15GB** ‚Üí Risque OOM si BERT + Mistral 7B\n",
    "- **Solution:** D√©sactiver BERT (`USE_BERT = False`) si probl√®me\n",
    "- **Sessions 12h** ‚Üí Sauvegarder dialogue important\n",
    "\n",
    "### ‚û°Ô∏è Prochaines √âtapes\n",
    "1. **Tester dialogue** : 5-10 √©changes avec Spinoza\n",
    "2. **V√©rifier qualit√©** : R√©ponses coh√©rentes avec STATE_IMAGE ?\n",
    "3. **Phase 1 (Vast.ai)** : Pipeline complet stabilis√© + benchmarks\n",
    "\n",
    "---\n",
    "\n",
    "**üí∞ Co√ªt:** 0‚Ç¨ (Colab gratuit GPU T4)\n",
    "\n",
    "**‚è±Ô∏è Temps:** ~3-4h (chargement + dialogue)\n",
    "\n",
    "**üéØ Objectif Phase 0:** Dialogue TRM fonctionnel ‚úÖ\n",
    "\n",
    "**üöÄ Vous pouvez maintenant discuter avec Spinoza via TRM !**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}